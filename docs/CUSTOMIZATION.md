# üé® Guia de Customiza√ß√£o

Este guia mostra como customizar o template ATTI para seu caso de uso espec√≠fico.

---

## 1. Substituir Base de Conhecimento

### Passo 1: Preparar Dados

Crie um arquivo `data/questions.json` com suas perguntas e respostas:

```json
[
  {
    "question": "Qual √© a pol√≠tica de f√©rias?",
    "answer": "Todos os funcion√°rios t√™m direito a 30 dias de f√©rias por ano, podendo ser fracionadas conforme acordado com o gestor."
  },
  {
    "question": "Como solicitar um dia de folga?",
    "answer": "Voc√™ pode solicitar atrav√©s do sistema RH com at√© 10 dias de anteced√™ncia."
  },
  {
    "question": "Qual √© o hor√°rio de trabalho?",
    "answer": "O hor√°rio padr√£o √© de 9h √†s 18h, com 1 hora de intervalo para almo√ßo."
  }
]
```

### Passo 2: Gerar Embeddings

```bash
cd backend
python orchestrator/generate_embeddings.py
cd ..
```

Isso cria um arquivo `faiss_index.pkl` com o √≠ndice otimizado.

### Passo 3: Fazer Deploy

```bash
cd backend
bash deploy/deploy_orchestrator.sh
cd ..
```

---

## 2. Gerar Embeddings FAISS

### O que s√£o Embeddings?

Embeddings s√£o representa√ß√µes num√©ricas de texto em um espa√ßo vetorial. O FAISS usa embeddings para busca sem√¢ntica r√°pida.

### Como Funciona

```python
# backend/orchestrator/generate_embeddings.py

from sentence_transformers import SentenceTransformer

# Carregar modelo de embeddings
model = SentenceTransformer('all-MiniLM-L6-v2')  # 384 dimens√µes

# Gerar embeddings para cada pergunta
embeddings = model.encode(questions)

# Criar √≠ndice FAISS
index = faiss.IndexFlatL2(384)
index.add(embeddings)

# Salvar √≠ndice
faiss.write_index(index, 'faiss_index.pkl')
```

### Customizar Modelo de Embeddings

```python
# backend/orchestrator/generate_embeddings.py

# Mudar para modelo maior (mais preciso, mais lento)
model = SentenceTransformer('all-mpnet-base-v2')  # 768 dimens√µes

# Ou modelo menor (mais r√°pido, menos preciso)
model = SentenceTransformer('all-MiniLM-L12-v2')  # 384 dimens√µes
```

---

## 3. Ajustar Prompts do LLM

### Prompt Padr√£o

```python
# backend/orchestrator/modal_orchestrator_api.py

SYSTEM_PROMPT = """
Voc√™ √© um assistente inteligente especializado em Recursos Humanos.
Responda perguntas dos funcion√°rios de forma clara, concisa e profissional.
Use as informa√ß√µes fornecidas como contexto.
Se n√£o souber a resposta, diga "N√£o tenho informa√ß√£o sobre isso".
"""

USER_PROMPT = """
Contexto:
{context}

Pergunta: {question}

Responda em portugu√™s.
"""
```

### Customizar para Seu Dom√≠nio

```python
# Para agente jur√≠dico
SYSTEM_PROMPT = """
Voc√™ √© um assistente jur√≠dico especializado em direito empresarial.
Forne√ßa informa√ß√µes precisas e cite as leis relevantes.
Sempre recomende consultar um advogado para quest√µes cr√≠ticas.
"""

# Para agente de suporte t√©cnico
SYSTEM_PROMPT = """
Voc√™ √© um especialista em suporte t√©cnico.
Forne√ßa solu√ß√µes passo a passo.
Se o problema persistir, recomende abrir um ticket.
"""

# Para agente de vendas
SYSTEM_PROMPT = """
Voc√™ √© um assistente de vendas amig√°vel e profissional.
Responda d√∫vidas sobre produtos e pre√ßos.
Ofere√ßa solu√ß√µes personalizadas para cada cliente.
"""
```

---

## 4. Trocar Modelos (ASR, TTS, LLM)

### Trocar Modelo LLM

```python
# backend/orchestrator/modal_orchestrator_api.py

# Padr√£o: Nemotron 3 Nano
MODEL_LLM = "nvidia/nemotron-3-nano-30b"

# Alternativas:
MODEL_LLM = "meta-llama/llama-2-70b"       # Llama 2 (mais poderoso)
MODEL_LLM = "mistralai/mistral-7b"         # Mistral (r√°pido)
MODEL_LLM = "gpt-3.5-turbo"                # GPT-3.5 (via API)
```

### Trocar Modelo ASR (Reconhecimento de Fala)

```python
# backend/asr/modal_asr_whisper.py

# Padr√£o: Whisper Large-V3
MODEL_ASR = "whisper-large-v3"

# Alternativas:
MODEL_ASR = "whisper-medium"               # Mais r√°pido, menos preciso
MODEL_ASR = "whisper-small"                # Muito r√°pido, menos preciso
MODEL_ASR = "whisper-base"                 # R√°pido, menos preciso
```

### Trocar Modelo TTS (S√≠ntese de Fala)

```python
# backend/tts/modal_tts_pyttsx3.py

# Padr√£o: pyttsx3
# Alternativas:
# - gTTS (Google Text-to-Speech)
# - ElevenLabs (mais natural)
# - Azure Text-to-Speech
# - AWS Polly

# Exemplo com ElevenLabs:
import elevenlabs

def synthesize_speech(text: str) -> bytes:
    audio = elevenlabs.generate(
        text=text,
        voice="Bella",  # Voz feminina
        model="eleven_monolingual_v1"
    )
    return audio
```

---

## 5. Customizar Frontend (Cores, Logo, Tema)

### Mudar Cores Prim√°rias

```css
/* frontend/src/index.css */

@layer base {
  :root {
    --primary: 37 99 235;        /* Azul */
    --secondary: 168 85 247;     /* Roxo */
    --accent: 59 130 246;        /* Azul claro */
    --destructive: 239 68 68;    /* Vermelho */
    --muted: 107 114 128;        /* Cinza */
    --background: 255 255 255;   /* Branco */
    --foreground: 15 23 42;      /* Preto */
  }

  .dark {
    --primary: 59 130 246;       /* Azul claro */
    --secondary: 168 85 247;     /* Roxo */
    --accent: 99 102 241;        /* √çndigo */
    --background: 15 23 42;      /* Preto */
    --foreground: 248 250 252;   /* Branco */
  }
}
```

### Mudar Logo

```tsx
// frontend/src/App.tsx

import logo from './assets/logo.png';

export default function App() {
  return (
    <div>
      <img src={logo} alt="Logo" className="h-8 w-8" />
      {/* ... */}
    </div>
  );
}
```

### Mudar Fontes

```html
<!-- frontend/index.html -->

<link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;600;700&display=swap" rel="stylesheet" />
```

```css
/* frontend/src/index.css */

@layer base {
  body {
    font-family: "Poppins", sans-serif;
  }
}
```

### Mudar Tema (Claro/Escuro)

```tsx
// frontend/src/App.tsx

import { ThemeProvider } from '@/components/theme-provider';

export default function App() {
  return (
    <ThemeProvider defaultTheme="dark">
      {/* ... */}
    </ThemeProvider>
  );
}
```

---

## 6. Fazer Deploy

### Deploy do Backend (Modal)

```bash
# 1. Instalar Modal CLI
pip install modal

# 2. Autenticar
modal token new

# 3. Deploy do Orquestrador
cd backend
bash deploy/deploy_orchestrator.sh

# 4. Deploy do Voice Pipeline
bash deploy/deploy_voice_pipeline.sh
cd ..
```

### Deploy do Frontend (Netlify)

```bash
# 1. Build
cd frontend
npm run build

# 2. Deploy
netlify deploy --prod --dir=dist

# 3. Configurar dom√≠nio (opcional)
netlify domain add seu-dominio.com
cd ..
```

---

## 7. Configurar Vari√°veis de Ambiente

### Frontend (.env)

```env
VITE_APP_NAME=Meu Agente RH
VITE_APP_DESCRIPTION=Assistente de Recursos Humanos
VITE_PRIMARY_COLOR=#2563eb
VITE_API_BASE_URL=https://seu-orquestrador.modal.run
VITE_VOICE_API_URL=https://seu-voice-pipeline.modal.run
```

### Backend (.env)

```env
MODEL_LLM=nvidia/nemotron-3-nano-30b
MODEL_ASR=whisper-large-v3
MODEL_TTS=pyttsx3
MODAL_API_KEY=seu_modal_api_key
FAISS_INDEX_PATH=./faiss_index.pkl
```

---

## 8. Exemplos Pr√°ticos por Dom√≠nio

### Agente de RH

**Base de Conhecimento:**
```json
[
  {"question": "Qual √© a pol√≠tica de f√©rias?", "answer": "..."},
  {"question": "Como solicitar licen√ßa maternidade?", "answer": "..."},
  {"question": "Qual √© o hor√°rio de trabalho?", "answer": "..."}
]
```

**Customiza√ß√µes:**
- Prompt: Especializado em pol√≠ticas de RH
- Cores: Azul corporativo
- Logo: Logo da empresa

### Agente Jur√≠dico

**Base de Conhecimento:**
```json
[
  {"question": "O que √© LGPD?", "answer": "..."},
  {"question": "Como fazer uma den√∫ncia?", "answer": "..."}
]
```

**Customiza√ß√µes:**
- Prompt: Especializado em direito
- Modelo LLM: Llama 2 70B (mais poderoso)
- Integra√ß√£o: APIs de jurisprud√™ncia

### Agente de Suporte T√©cnico

**Base de Conhecimento:**
```json
[
  {"question": "Como resetar minha senha?", "answer": "..."},
  {"question": "O sistema est√° fora do ar?", "answer": "..."}
]
```

**Customiza√ß√µes:**
- Prompt: Especializado em suporte t√©cnico
- Integra√ß√£o: Ticket system
- Analytics: Rastreamento de problemas

---

## 9. Monitoramento e Testes

### Testar Localmente

```bash
# Frontend
cd frontend
npm run dev

# Backend (em outro terminal)
cd backend
modal serve modal_orchestrator_api.py
```

### Testar em Produ√ß√£o

```bash
# Testar orquestrador
curl -X POST https://seu-orquestrador.modal.run/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Qual √© a pol√≠tica de f√©rias?"}'

# Testar voice pipeline
curl -X POST https://seu-voice-pipeline.modal.run/process-audio-base64 \
  -H "Content-Type: application/json" \
  -d '{"audio": "base64_encoded_audio"}'
```

---

## 10. Troubleshooting

### Problema: Respostas ruins

**Solu√ß√£o:**
1. Verifique a qualidade da base de conhecimento
2. Ajuste o prompt do LLM
3. Teste com um modelo LLM mais poderoso

### Problema: ASR n√£o reconhece bem

**Solu√ß√£o:**
1. Verifique a qualidade do √°udio
2. Tente com Whisper Large-V3 (mais preciso)
3. Ajuste o idioma

### Problema: Deploy falha

**Solu√ß√£o:**
1. Verifique credenciais (Modal, Netlify)
2. Verifique depend√™ncias (requirements.txt, package.json)
3. Verifique logs: `modal logs`

---

## Pr√≥ximas Etapas

1. ‚úÖ Customizar base de conhecimento
2. ‚úÖ Ajustar prompts
3. ‚úÖ Trocar modelos (se necess√°rio)
4. ‚úÖ Customizar frontend
5. ‚úÖ Fazer deploy
6. ‚úÖ Testar e iterar

**Pronto para come√ßar? Clone o template e comece a customizar!** üöÄ
